{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook contains various scripts to obtain the static analysis characteristics of the WatchDog data.\n",
    "Make sure that you have downloaded the two bson files from the server: `users.bson` and `events.bson` and that they exist in the directory this notebook is in.\n",
    "\n",
    "The first step is to load in all required packages. It should be rarely needed to rerun this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import plotly\n",
    "import pymongo\n",
    "import bson\n",
    "import json\n",
    "import operator\n",
    "import re\n",
    "import copy\n",
    "import pylab\n",
    "import scipy.stats\n",
    "from datetime import datetime\n",
    "from collections import Counter,defaultdict,OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the bson files as well as the eclipse messages dictionary obtained from [the internal Eclipse compiler messages.properties](https://github.com/eclipse/eclipse.jdt.core/blob/efc9b650d8590a5670b5897ab6f8c0fb0db2799d/org.eclipse.jdt.core/compiler/org/eclipse/jdt/internal/compiler/problem/messages.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users.bson', 'rb') as user_file:\n",
    "    users = bson.decode_all(user_file.read())\n",
    "with open('events.bson', 'rb') as events_file:\n",
    "    events = bson.decode_all(events_file.read())\n",
    "with open('eclipse-messages.json', 'r') as messages_file:\n",
    "    eclipse_messages = json.load(messages_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions are available for general visualization. The first one is used to generate a histogram with the top 25 items, as well as the full histogram thereafter. The second function can output a dictionary in a human-friendly table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts(ylabel, xlabel, count_list, top_n_items = 0, should_sort = True, print_index=False):\n",
    "    if (should_sort):\n",
    "        labels, values = zip(*sorted(Counter(count_list).items(), key=lambda tup: tup[1], reverse = True))\n",
    "    else:\n",
    "        labels, values = zip(*count_list)\n",
    "    truncated_labels = list(map(lambda label: label[:50], labels))\n",
    "\n",
    "    indexes = np.arange(len(labels))\n",
    "    \n",
    "    if (top_n_items != 0):\n",
    "        first_n_indexes = indexes[:top_n_items]\n",
    "        first_n_values = values[:top_n_items]\n",
    "        first_n_labels = labels[:top_n_items]\n",
    "        \n",
    "        top_dictionary = defaultdict(int)\n",
    "        for index in range(0, top_n_items):\n",
    "            top_dictionary[first_n_labels[index]] = first_n_values[index]\n",
    "        print_dictionary_as_table('Warning category', 'Frequency', OrderedDict(sorted(top_dictionary.items(), key=operator.itemgetter(1), reverse=True)), print_index=print_index)\n",
    "\n",
    "        truncated_first_n_labels = list(map(lambda label: label[:75], first_n_labels))\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        plt.barh(first_n_indexes, first_n_values)\n",
    "        plt.yticks(first_n_indexes, truncated_first_n_labels)\n",
    "        plt.xlabel(ylabel)\n",
    "        plt.ylabel(xlabel)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(('img/top-' + ylabel + xlabel + '.png').replace(' ', '-'))\n",
    "\n",
    "    fig = plt.figure(figsize=(13,10))\n",
    "    plt.barh(indexes, values)\n",
    "    plt.yticks(indexes, truncated_labels)\n",
    "    plt.xlabel(ylabel)\n",
    "    plt.ylabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(('img/' + ylabel + xlabel + '.png').replace(' ', '-'))\n",
    "\n",
    "def print_dictionary_as_table(header1, header2, dictionary, anonymize=False, print_index=False):\n",
    "    print(('Index & ' if print_index else '') + header1 + ' & ' + header2 + ' \\\\\\\\ \\hline')\n",
    "    for row in [(str(index + 1) + ' & ' if print_index else '') + ('{:<' + str(len(header1)) + '}').format(index if anonymize else key.replace('{', '\\\\{').replace('}', '\\\\}')) + ' & ' + str(dictionary[key] if ((type(dictionary[key]) == int) or (type(dictionary[key]) == float)) else len(dictionary[key])) + ' \\\\\\\\' for index,key in enumerate(dictionary)]:\n",
    "        print(row)\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun 15 17:09:21 2017\n",
    "\n",
    "@author: apbar\n",
    "Copied source code from https://github.com/BarataAP/dunn\n",
    "\"\"\"\n",
    "\n",
    "def makeRanks(*args):\n",
    "    \"\"\"\n",
    "    Converts tuple of arrays of values into ranks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample1, sample2, ... : tuple_array_like\n",
    "        The sample data, possibly with different lengths\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    sample1, sample2, ... : tuple_array_like\n",
    "        The ranked sample data \n",
    "\n",
    "    \"\"\"\n",
    "    Ranks = []\n",
    "    RanksF = []\n",
    "    try:\n",
    "        for data in sorted(args[0]):\n",
    "            ranks = {}\n",
    "            rank = 0\n",
    "            for pt in data:\n",
    "                rank = rank + 1 \n",
    "                if pt in ranks.keys():\n",
    "                    ranks[pt] = ranks[pt] + [rank]\n",
    "                else:\n",
    "                    ranks[pt] = [rank]\n",
    "            Ranks.append(ranks)\n",
    "        for ranks in Ranks:\n",
    "            keys = sorted(ranks.keys())\n",
    "            protoRanks = []\n",
    "            for key in keys:\n",
    "                value = np.mean(ranks[key])\n",
    "                for i in range(0, len(ranks[key])):\n",
    "                    protoRanks.append(value)\n",
    "            RanksF.append(protoRanks)\n",
    "    except:\n",
    "        for data in sorted(args):\n",
    "            ranks = {}\n",
    "            rank = 0\n",
    "            for pt in data:\n",
    "                rank = rank + 1 \n",
    "                if pt in ranks.keys():\n",
    "                    ranks[pt] = ranks[pt] + [rank]\n",
    "                else:\n",
    "                    ranks[pt] = [rank]\n",
    "            Ranks.append(ranks)\n",
    "        for ranks in Ranks:\n",
    "            keys = sorted(ranks.keys())\n",
    "            protoRanks = []\n",
    "            for key in keys:\n",
    "                value = np.mean(ranks[key])\n",
    "                for i in range(0, len(ranks[key])):\n",
    "                    protoRanks.append(value)\n",
    "            RanksF.append(protoRanks)\n",
    "    return tuple(RanksF)\n",
    "    \n",
    "def dunn(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Performs a two-tailed Dunn's test for stochastic dominance.\n",
    "\n",
    "    Dunn’s test (1964) tests for stochastic dominance and reports the results\n",
    "    among multiple pairwise comparisons after a rejected null hypothesis for a \n",
    "    Kruskal-Wallis test for stochastic dominance among k groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample1, sample2, ... : array_like\n",
    "        The sample data, possibly with different lengths\n",
    "    \"none\", \"fdr\", ... : string_like\n",
    "        Type of correction to use.\n",
    "        Default is correction=\"none\",\n",
    "        \"bonferroni\" -> bonferroni correction,\n",
    "        \"fdr\" -> (Benjaminyi-Hochberg false discovery rate method)\n",
    "    label1, label2, ... : array_string_like\n",
    "        Group labels to use when displaying or saving results\n",
    "        Default is labels=(0, 1, ..., n)\n",
    "        n = len(groups)\n",
    "    True, False: bool_like\n",
    "        Prints results on screen when True\n",
    "        Default is display=True\n",
    "    False, True, \"fileName\": bool_string_like\n",
    "        Saves results onto csv file\n",
    "        Default is save=False\n",
    "        True -> labels will be used as filename\n",
    "        \"myFile\" -> myFile.csv will be created\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dunn: hash_like\n",
    "        Dunn's multiple pairwaise test statistics, p-values, and q-values (corrections)\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1]  https://stats.stackexchange.com/tags/dunn-test/info\n",
    "    .. [2]  Dunn, O. J. (1961). Multiple comparisons among means.\n",
    "            Journal of the American Statistical Association, 56(293):52–64.\n",
    "    .. [3]  Dunn, O. J. (1964). Multiple comparisons using rank sums.\n",
    "            Technometrics, 6(3):241–252.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = [0.28551035, 0.338524035, 0.088631321, 0.205930807, 0.363240102]\n",
    "    >>> b = [0.52173913, 0.763358779, 0.325436786, 0.425305688, 0.378071834]\n",
    "    >>> c = [0.98911968, 1.192718142, 0.788288288, 0.549176236, 0.544588155]\n",
    "    >>> d = [1.26705653, 1.625320787, 1.266108976, 1.154187629, 1.268489431]\n",
    "    >>> e = [1.25697569, 1.265897356, 1.237814561, 0.954612564, 2.365415457]\n",
    "    >>> f = dunn(a,b,c,d,e)\n",
    "    \n",
    "          1       2       3       4       \n",
    "       0  -0.9882 -2.1054 -3.8241 -3.3944 0\n",
    "       1  -       -1.1171 -2.8358 -2.4061 1\n",
    "       2  -       -       -1.7187 -1.2890 2\n",
    "       3  -       -       -       0.42967 3\n",
    "          1       2       3       4       \n",
    "    \n",
    "    Dunn test H0 z-statistic\n",
    "    \n",
    "    \n",
    "          1       2       3       4       \n",
    "       0  0.32304 0.03526 0.00013 0.00069 0\n",
    "       1  -       0.26393 0.00457 0.01612 1\n",
    "       2  -       -       0.08567 0.19740 2\n",
    "       3  -       -       -       0.66744 3\n",
    "          1       2       3       4       \n",
    "    \n",
    "    Adjustment method for p-value: none\n",
    "    \n",
    "    >>> groups = a,b,c,d,e\n",
    "    >>> g = dunn(groups,correction=\"fdr\",labels=(\"a\",\"b\",\"c\",\"d\",\"e\"),display=True,save=False)\n",
    "    \n",
    "          b       c       d       e       \n",
    "       a  -0.9882 -2.1054 -3.8241 -3.3944 a\n",
    "       b  -       -1.1171 -2.8358 -2.4061 b\n",
    "       c  -       -       -1.7187 -1.2890 c\n",
    "       d  -       -       -       0.42967 d\n",
    "          b       c       d       e       \n",
    "    \n",
    "    Dunn test H0 z-statistic\n",
    "    \n",
    "    \n",
    "          b       c       d       e       \n",
    "       a  0.35893 0.07052 0.00131 0.00344 a\n",
    "       b  -       0.32992 0.01524 0.04030 b\n",
    "       c  -       -       0.14279 0.28199 c\n",
    "       d  -       -       -       0.66744 d\n",
    "          b       c       d       e       \n",
    "    \n",
    "    Adjustment method for p-value: fdr\n",
    "    \n",
    "    >>> g\n",
    "    {0: {'ID': 'a-b',\n",
    "      'p-value': 0.32303584413413144,\n",
    "      'q-value': 0.35892871570459051,\n",
    "      'statistic': -0.98823852617441732},\n",
    "     1: {'ID': 'a-c',\n",
    "      'p-value': 0.035258440790219898,\n",
    "      'q-value': 0.070516881580439797,\n",
    "      'statistic': -2.1053777296759324},\n",
    "     2: {'ID': 'a-d',\n",
    "      'p-value': 0.00013127544861251964,\n",
    "      'q-value': 0.0013127544861251965,\n",
    "      'statistic': -3.8240534273705715},\n",
    "     3: {'ID': 'a-e',\n",
    "      'p-value': 0.0006878304609215692,\n",
    "      'q-value': 0.0034391523046078459,\n",
    "      'statistic': -3.3943845029469117},\n",
    "     4: {'ID': 'b-c',\n",
    "      'p-value': 0.26393481049044942,\n",
    "      'q-value': 0.32991851311306175,\n",
    "      'statistic': -1.1171392035015151},\n",
    "     5: {'ID': 'b-d',\n",
    "      'p-value': 0.0045708928878404912,\n",
    "      'q-value': 0.015236309626134972,\n",
    "      'statistic': -2.8358149011961538},\n",
    "     6: {'ID': 'b-e',\n",
    "      'p-value': 0.016121821274057219,\n",
    "      'q-value': 0.040304553185143047,\n",
    "      'statistic': -2.4061459767724944},\n",
    "     7: {'ID': 'c-d',\n",
    "      'p-value': 0.085673439552316863,\n",
    "      'q-value': 0.14278906592052812,\n",
    "      'statistic': -1.7186756976946389},\n",
    "     8: {'ID': 'c-e',\n",
    "      'p-value': 0.19739573184449921,\n",
    "      'q-value': 0.28199390263499891,\n",
    "      'statistic': -1.2890067732709791},\n",
    "     9: {'ID': 'd-e',\n",
    "      'p-value': 0.66743649170988251,\n",
    "      'q-value': 0.66743649170988251,\n",
    "      'statistic': 0.42966892442365973}}\n",
    "     \n",
    "    \"\"\"  \n",
    "    dunn = {}\n",
    "    groups = copy.deepcopy(args) #tuple of len k\n",
    "    if str(type(groups[0][0])) == \"<type 'list'>\" or str(type(groups[0][0])) == \"<type 'tuple'>\":\n",
    "        groups = groups[0]\n",
    "    if \"labels\" not in kwargs.keys():\n",
    "        kwargs[\"labels\"] = []\n",
    "        for i in range(0, len(groups)):\n",
    "            protoL = str(i)\n",
    "            kwargs[\"labels\"].append(protoL)\n",
    "    else:\n",
    "        if len(kwargs[\"labels\"]) != len(groups):\n",
    "            raise ValueError(\"length of groups and length of labels must be the same\")\n",
    "        else:\n",
    "            for label in kwargs[\"labels\"]:\n",
    "                if str(type(label)) != \"<type 'str'>\":\n",
    "                    raise ValueError(\"each label must be a string\")\n",
    "    for i in range(0, len(groups)):\n",
    "        group = groups[i]\n",
    "        while group.count(None) > 0 :\n",
    "            group.remove(None)\n",
    "        while group.count(np.nan) > 0 :\n",
    "            group.remove(np.nan)\n",
    "        if len(group) < 5:\n",
    "            print(Warning(\"WARNING: at least one group has fewer than 5 proper elements\"))\n",
    "            print(kwargs[\"labels\"][i], group)\n",
    "        if len(group) == 0:\n",
    "            raise ValueError(\"at least one group has no proper values\")\n",
    "    key = 0\n",
    "    metaG = []\n",
    "    for i in range(0, len(groups)):\n",
    "        metaG = metaG + groups[i]\n",
    "    metaGR = makeRanks(metaG)[0]\n",
    "    n = len(metaGR)\n",
    "    ties = 0.0\n",
    "    uniqueR = list(set(metaGR))\n",
    "    for elem in uniqueR:\n",
    "        if metaGR.count(elem) > 1:\n",
    "            ties = ties + (metaGR.count(elem)**3 - metaGR.count(elem))\n",
    "        else:\n",
    "            pass\n",
    "    for i in range(0, len(groups)-1): #for every group in groups, excluding last\n",
    "        grp1 = sorted(list(groups[i]))\n",
    "        n1 = float(len(grp1))\n",
    "        ranks1 = []\n",
    "        for k1 in range(0, len(grp1)):\n",
    "            point1 = grp1[k1]\n",
    "            idx1 = metaG.index(point1)\n",
    "            rank1 = metaGR[idx1]\n",
    "            ranks1.append(rank1)   \n",
    "        meanR1 = np.mean(ranks1)\n",
    "        for j in range(i+1, len(groups)): #for every group following grp1\n",
    "            grp2 = sorted(list(groups[j]))\n",
    "            n2 = float(len(grp2))\n",
    "            ranks2 = []\n",
    "            for k2 in range(0, len(grp2)):\n",
    "                point2 = grp2[k2]\n",
    "                idx2 = metaG.index(point2)\n",
    "                rank2 = metaGR[idx2]\n",
    "                ranks2.append(rank2)\n",
    "            meanR2 = np.mean(ranks2)\n",
    "            y = meanR1 - meanR2\n",
    "            g = ((((n*(n+1))/12.0) - (ties/(12.0*(n-1)))) * (1.0/n1 + 1.0/n2))**0.5\n",
    "            stat = y/g\n",
    "            if scipy.stats.norm.cdf(stat) > 0.5:\n",
    "                p = 2*(1 - scipy.stats.norm.cdf(stat))\n",
    "            else:\n",
    "                p = 2*(scipy.stats.norm.cdf(stat))\n",
    "            dunn[key] = {}\n",
    "            dunn[key][\"ID\"] = kwargs[\"labels\"][i]+\"-\"+kwargs[\"labels\"][j]\n",
    "            dunn[key][\"statistic\"] = stat\n",
    "            dunn[key][\"p-value\"] = p\n",
    "            key = key + 1\n",
    "    if \"correction\" not in kwargs.keys():\n",
    "        kwargs[\"correction\"] = \"none\"  \n",
    "    if kwargs[\"correction\"] != \"none\":\n",
    "        m = float(len(dunn))\n",
    "        if kwargs[\"correction\"] == \"bonferroni\":\n",
    "            keys = sorted(dunn.keys())\n",
    "            for key in keys:\n",
    "                dunn[key][\"q-value\"] = dunn[key][\"p-value\"] * m\n",
    "                if dunn[key][\"q-value\"] > 1:\n",
    "                    dunn[key][\"q-value\"] = 1.0\n",
    "        elif kwargs[\"correction\"] == \"fdr\":\n",
    "            ps = []\n",
    "            keys = sorted(dunn.keys())\n",
    "            for key in keys:\n",
    "                ps.append(dunn[key][\"p-value\"])\n",
    "                \n",
    "            ps = sorted(ps, reverse=True)\n",
    "            pTop = ps[0]\n",
    "            for key in keys:\n",
    "                i = ps.index(dunn[key][\"p-value\"]) + 1\n",
    "                q = dunn[key][\"p-value\"] * (m/(m+1-i))\n",
    "                if q > pTop:\n",
    "                    q = pTop\n",
    "                else:\n",
    "                    pass\n",
    "                dunn[key][\"q-value\"] = q\n",
    "        else:\n",
    "            raise ValueError(\"correction keyword must be 'bonferroni' or 'fdr'\")\n",
    "    if \"display\" not in kwargs.keys():\n",
    "        kwargs[\"display\"] = True\n",
    "    if kwargs[\"display\"] == True:\n",
    "        print(\"\")\n",
    "        lenLabels = []\n",
    "        for label in kwargs[\"labels\"]:\n",
    "            lenLabels.append(len(label))\n",
    "        maxLen = max(lenLabels)\n",
    "        if maxLen < 3:\n",
    "            maxLen = 4\n",
    "        line1 = \"  \"\n",
    "        for i in range(0, maxLen):\n",
    "            line1 = line1 + \" \"\n",
    "        for i in range(1, len(groups)):\n",
    "            variable = kwargs[\"labels\"][i]\n",
    "            while len(variable) < maxLen:\n",
    "                variable = variable + \" \"\n",
    "            variable = variable + \"    \"\n",
    "            line1 = line1 + variable\n",
    "        print(line1)\n",
    "        k = 0\n",
    "        for i in range(0, len(groups)-1):\n",
    "            line = kwargs[\"labels\"][i]\n",
    "            while len(line) < maxLen:\n",
    "                line = \" \" + line\n",
    "            line = line + \"  \"\n",
    "            if i != 0:\n",
    "                for some in range(0, i):\n",
    "                    blank = \"-\"\n",
    "                    while len(blank) < maxLen+4:\n",
    "                        blank = blank + \" \"\n",
    "                    line = line + blank\n",
    "            for j in range(i+1, len(groups)):\n",
    "                if maxLen < 4 :\n",
    "                    decimalNeg = \"{0:.4f}\"\n",
    "                    decimalPos = \"{0:.5f}\"\n",
    "                else:    \n",
    "                    decimalNeg = \"{0:.\" + str(maxLen) + \"f}\"\n",
    "                    decimalPos = \"{0:.\" + str((maxLen+1)) + \"f}\"\n",
    "                if dunn[k][\"statistic\"] < 0:\n",
    "                    line = line + decimalNeg.format(dunn[k][\"statistic\"]) + \" \"\n",
    "                else:\n",
    "                    line = line + decimalPos.format(dunn[k][\"statistic\"]) + \" \"\n",
    "                k = k + 1\n",
    "            line = line + kwargs[\"labels\"][i]\n",
    "            print(line)\n",
    "        line1 = \"  \"\n",
    "        for i in range(0, maxLen):\n",
    "            line1 = line1 + \" \"\n",
    "        for i in range(1, len(groups)):\n",
    "            variable = kwargs[\"labels\"][i]\n",
    "            while len(variable) < maxLen:\n",
    "                variable = variable + \" \"\n",
    "            variable = variable + \"    \"\n",
    "            line1 = line1 + variable\n",
    "        print(line1)\n",
    "        print(\"\\nDunn test H0 z-statistic\\n\")\n",
    "        print(\"\")\n",
    "        line1 = \"  \"\n",
    "        for i in range(0, maxLen):\n",
    "            line1 = line1 + \" \"\n",
    "        for i in range(1, len(groups)):\n",
    "            variable = kwargs[\"labels\"][i]\n",
    "            while len(variable) < maxLen:\n",
    "                variable = variable + \" \"\n",
    "            variable = variable + \"    \"\n",
    "            line1 = line1 + variable\n",
    "        print(line1)\n",
    "        k = 0\n",
    "        for i in range(0, len(groups)-1):\n",
    "            line = kwargs[\"labels\"][i]\n",
    "            while len(line) < maxLen:\n",
    "                line = \" \" + line\n",
    "            line = line + \"  \"\n",
    "            if i != 0:\n",
    "                for some in range(0, i):\n",
    "                    blank = \"-\"\n",
    "                    while len(blank) < maxLen+4:\n",
    "                        blank = blank + \" \"\n",
    "                    line = line + blank\n",
    "            for j in range(i+1, len(groups)):\n",
    "                if maxLen < 4 :\n",
    "                    decimalNeg = \"{0:.4f}\"\n",
    "                    decimalPos = \"{0:.5f}\"\n",
    "                else:    \n",
    "                    decimalNeg = \"{0:.\" + str(maxLen) + \"f}\"\n",
    "                    decimalPos = \"{0:.\" + str((maxLen+1)) + \"f}\"\n",
    "                if kwargs[\"correction\"] == \"none\":\n",
    "                    if dunn[k][\"p-value\"] < 0:\n",
    "                        line = line + decimalNeg.format(dunn[k][\"p-value\"]) + \" \"\n",
    "                    else:\n",
    "                        line = line + decimalPos.format(dunn[k][\"p-value\"]) + \" \"\n",
    "                else:\n",
    "                    if dunn[k][\"q-value\"] < 0:\n",
    "                        line = line + decimalNeg.format(dunn[k][\"q-value\"]) + \" \"\n",
    "                    else:\n",
    "                        line = line + decimalPos.format(dunn[k][\"q-value\"]) + \" \"\n",
    "                k = k + 1\n",
    "            line = line + kwargs[\"labels\"][i]\n",
    "            print(line)\n",
    "        line1 = \"  \"\n",
    "        for i in range(0, maxLen):\n",
    "            line1 = line1 + \" \"\n",
    "        for i in range(1, len(groups)):\n",
    "            variable = kwargs[\"labels\"][i]\n",
    "            while len(variable) < maxLen:\n",
    "                variable = variable + \" \"\n",
    "            variable = variable + \"    \"\n",
    "            line1 = line1 + variable\n",
    "        print(line1)\n",
    "        print(\"\\nAdjustment method for p-value:\", kwargs[\"correction\"], \"\\n\")\n",
    "    if \"save\" in kwargs.keys():\n",
    "        if kwargs[\"save\"] != False:    \n",
    "            if kwargs[\"save\"] == True:\n",
    "                fileName = \"\"\n",
    "                for label in kwargs[\"labels\"]:\n",
    "                    fileName = fileName + str(label) + \"_vs_\"\n",
    "                fileName = fileName[:-4] + \".csv\"\n",
    "            elif str(type(kwargs[\"save\"])) == \"<type 'str'>\":\n",
    "                fileName = kwargs[\"save\"]\n",
    "                if fileName[-4:] != \".csv\":\n",
    "                    fileName = fileName + \".csv\"\n",
    "            else:\n",
    "                raise ValueError(\"save arg must be either True, or string\")\n",
    "            op = open(fileName, 'w')\n",
    "            labels = kwargs[\"labels\"]\n",
    "            line1 = \"statistic,\"\n",
    "            for label in labels[1:]:\n",
    "                line1 = line1 + label + \",\"\n",
    "            line1 = line1[:-1] + \"\\n\"\n",
    "            op.write(line1)\n",
    "            k = 0\n",
    "            for i in range(0, len(groups)-1):\n",
    "                line = labels[i] + \",\"\n",
    "                if i != 0:\n",
    "                    for blank in range(0, i):\n",
    "                        line = line + \",\"\n",
    "                for j in range(i+1, len(groups)):\n",
    "                    line = line + str(dunn[k][\"statistic\"]) + \",\"\n",
    "                    k = k + 1\n",
    "                line = line[:-1] + \"\\n\"\n",
    "                op.write(line)    \n",
    "            op.write(\"\\n\")\n",
    "            line1 = \"p-value,\"\n",
    "            for label in labels[1:]:\n",
    "                line1 = line1 + label + \",\"\n",
    "            line1 = line1[:-1] + \"\\n\"\n",
    "            op.write(line1)\n",
    "            k = 0\n",
    "            for i in range(0, len(groups)-1):\n",
    "                line = labels[i] + \",\"\n",
    "                if i != 0:\n",
    "                    for blank in range(0, i):\n",
    "                        line = line + \",\"\n",
    "                for j in range(i+1, len(groups)):\n",
    "                    if kwargs[\"correction\"] == \"none\":\n",
    "                        line = line + str(dunn[k][\"p-value\"]) + \",\"\n",
    "                    else:\n",
    "                        line = line + str(dunn[k][\"q-value\"]) + \",\"\n",
    "                    k = k + 1\n",
    "                line = line[:-1] + \"\\n\"\n",
    "                op.write(line)    \n",
    "            op.close()               \n",
    "    return dunn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First obtain the static analysis events we are interested in. The types are `sa-wc` and `sa-wr`. A previous version of WatchDog was deployed for IntelliJ, but this version did not include the full data characteristics that we needed. Therefore, we have to filter for `'warning' in event`, as this version of WatchDog does not have this field in the event. Later versions of WatchDog do.\n",
    "\n",
    "The events can be filtered by `userId`. This is used as in previous analyses 1 user generated a significant portion of the warnings, which would result in a misreprentation of the full developer population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sa_events = list(filter(lambda event: (event['userId'] != '5a08e78c0e305bfcd5865a105ca44fc9f042b1d7') and (event['userId'] != 'd407d447189a3aa9f047339934db73bb48b80054'), events))\n",
    "sa_events = list(filter(lambda event: (event['et'] == 'sa-wc' or event['et'] == 'sa-wr') and ('warning' in event), all_sa_events))\n",
    "sa_snapshot_events = list(filter(lambda event: (event['et'] == 'sa-snap'), all_sa_events))\n",
    "num_snapshot_events = len(sa_snapshot_events)\n",
    "num_warnings_in_snapshot_events = len([warning for event in sa_snapshot_events for warning in event['warnings']])\n",
    "num_empty_snapshot_events = len(list(filter(lambda event: len(event['warnings']) > 0, sa_snapshot_events)))\n",
    "print('Number of static analysis events: ' + str(len(sa_events)))\n",
    "print('Number of warning creation events: ' + str(len(list(filter(lambda event: event['et'] == 'sa-wc', sa_events)))))\n",
    "print('Number of warning removal events: ' + str(len(list(filter(lambda event: event['et'] == 'sa-wr', sa_events)))))\n",
    "print('Number of warning snapshot events: ' + str(num_snapshot_events))\n",
    "print('Number of warnings in warning snapshot events: ' + str(num_warnings_in_snapshot_events))\n",
    "print('Number of warning snapshot events with zero warnings: ' + str(num_empty_snapshot_events))\n",
    "print('Percentage of non-empty snapshot events: ' + str(round((num_snapshot_events - num_empty_snapshot_events) / num_snapshot_events * 100, 2)))\n",
    "print('Average number of warnings per snapshot: ' + str(round(num_warnings_in_snapshot_events / (num_snapshot_events - num_empty_snapshot_events), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following query to obtain the total number of development hours generated by the developers:\n",
    "```\n",
    "db.intervals.aggregate([\n",
    "  {\n",
    "    $match: {\n",
    "      it: \"eo\",\n",
    "      ss: {\n",
    "        $in: db.events.distinct(\"ss\", {et: {$in: [\"sa-wc\", \"sa-wr\", \"sa-snap\"]}})\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    $project: {\n",
    "      duration: {\n",
    "        $divide: [\n",
    "          {\n",
    "            $subtract: [\"$te\", \"$ts\"]\n",
    "          },\n",
    "          60 * 60 * 1000\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    $group: {\n",
    "      _id: null,\n",
    "      timeTotal: {\n",
    "        $sum: \"$duration\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first analysis we do is plotting a histogram of the warning categories. The y-axis shows the warning that is being generated. Since Eclipse normally uses integers to represent a category, use the previously loaded `eclipse-messages.json` data to map back to the full message pattern. This makes reading the graph significantly easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_events_with_classifications = list(filter(lambda event: event['warning']['type'] != 'unknown', sa_events))\n",
    "\n",
    "print('Number of classified warnings: ' + str(len(sa_events_with_classifications)))\n",
    "len_no_classifications = len(sa_events) - len(sa_events_with_classifications)\n",
    "print('Fraction of events with unknown classification: ' + str(round(len_no_classifications / len(sa_events) * 100, 2)))\n",
    "\n",
    "def stringify_warning(warning):\n",
    "    return eclipse_messages[str(int(warning) - 1)] if warning.isdigit() else warning\n",
    "\n",
    "def stringify_warnings(warnings):\n",
    "    return map(stringify_warning, warnings)\n",
    "\n",
    "sa_events_labeled_classifications = list(stringify_warnings(map(lambda event: event['warning']['type'], sa_events_with_classifications)))\n",
    "\n",
    "print('Number of CheckStyle warnings: ' + str(len(list(filter(lambda warning: warning.startswith('checkstyle'), sa_events_labeled_classifications)))))\n",
    "\n",
    "print()\n",
    "\n",
    "plot_counts('Number of events in category', 'Warning category', sa_events_labeled_classifications, 25, print_index=True)\n",
    "\n",
    "sa_events_removed = Counter(stringify_warnings(map(lambda event: event['warning']['type'], filter(lambda event: event['et'] == 'sa-wr', sa_events_with_classifications))))\n",
    "sa_events_created = Counter(stringify_warnings(map(lambda event: event['warning']['type'], filter(lambda event: event['et'] == 'sa-wc', sa_events_with_classifications))))\n",
    "\n",
    "percentage_removed = []\n",
    "top_warnings, values = zip(*sorted(Counter(sa_events_labeled_classifications).items(), key=lambda tup: tup[1], reverse = True))\n",
    "indexes_top_warnings = np.arange(len(top_warnings))\n",
    "top_warning_names = [top_warnings[index] for index in indexes_top_warnings[:25]]\n",
    "\n",
    "\n",
    "for key in top_warning_names:\n",
    "    if (key in sa_events_created):\n",
    "        percentage = min(1.0, sa_events_removed[key] / sa_events_created[key])\n",
    "        percentage_removed.insert(0, (key, percentage))\n",
    "\n",
    "plot_counts('Fraction of warnings resolved', 'Warning category', percentage_removed, should_sort = False)\n",
    "print('Number of warning categories with majority resolved: ' + str(len(list(filter(lambda p: p >=0.5, map(lambda tup: tup[1], percentage_removed))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second analysis is regarding the location of the warnings in a file. The location is relative, meaning that we take the line as percentage of the full file length. Since some files do not have the file length information, disregard these values. There is also a heatmap for the warning snapshots, which thus includes the same information but then for unresolved warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHeatMap(name, typetext, warnings):\n",
    "    hist, edges = np.histogram(warnings, np.arange(0, 1.01, 0.01))\n",
    "    hist=hist[np.newaxis,:]\n",
    "    plt.imshow(hist, aspect = \"auto\", cmap=\"viridis\", extent=[0,1,0,100])\n",
    "    plt.gca().set_yticks([])\n",
    "    plt.xlabel('Position of ' + typetext + ' relative to total file length')\n",
    "    plt.ylabel('Frequency of occurrence')\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    fig.savefig('img/file-heatmap-' + name)\n",
    "\n",
    "def get_relative_line(event):\n",
    "    if (event['warning']['doctotal'] == -1):\n",
    "        return round(event['warning']['line'] / event['doc']['sloc'], 2)\n",
    "    return round(event['warning']['line'] / event['warning']['doctotal'], 2)\n",
    "\n",
    "print('Warnings added/removed relative to file')\n",
    "sa_events_doctotal = filter(lambda event: 'doctotal' in event['warning'] and abs(event['doc']['sloc']) != 1 and event['doc']['sloc'] != 0 and event['warning']['line'] != -1, sa_events)\n",
    "showHeatMap('created-removed', 'warning', list(map(get_relative_line, sa_events_doctotal)))\n",
    "\n",
    "print('Warning snapshots of all warnings')\n",
    "sa_snapshots = list(filter(lambda event: event['et'] == 'sa-snap', events))\n",
    "snapshots_relative_loc = []\n",
    "for event in sa_snapshots:\n",
    "    for warning in event['warnings']:\n",
    "        if abs(event['doc']['sloc'] != -1 and event['doc']['sloc'] != 0):\n",
    "            percentage = round(warning['line'] / event['doc']['sloc'], 2)\n",
    "            if (percentage < 1):\n",
    "                snapshots_relative_loc.append(percentage)\n",
    "showHeatMap('snapshots', 'warning', snapshots_relative_loc)\n",
    "\n",
    "relative_positions_projects = np.genfromtxt('positions_relative.csv', delimiter=',')\n",
    "print('Relative positions of class declaration in ' + str(len(relative_positions_projects)) + ' java files')\n",
    "showHeatMap('open-source-projects', 'class declaration', relative_positions_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick overview of our developer population, plot the number of events per developer. Use this data to spot potential data skews and act accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_counts('Number of events per user', 'User ID', list(map(lambda event: event['userId'] , sa_events)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are tracking warning time. We only have this data for warning removals, as these events have a previous creation timestamp to compare to. We split the data into two: for the removals that have a creation time and for those that do not. Print the population percentage of time-calculated warnings, to get a sense of how many warnings are actually resolved without previous information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_warning_events = list(filter(lambda event: event['et'] == 'sa-wr', sa_events))\n",
    "life_time_events = list(map(lambda event: event['warning']['diff'], created_warning_events))\n",
    "has_time_diff = list(filter(lambda time: time != -1, life_time_events))\n",
    "has_no_time_diff = list(filter(lambda time: time == -1, life_time_events))\n",
    "\n",
    "number_of_time_diff = len(has_time_diff)\n",
    "number_of_no_time_diff = len(has_no_time_diff)\n",
    "print('Number of warnings which have a time diff: ' + str(number_of_time_diff))\n",
    "print('Number of warnings which do not have a time diff: ' + str(number_of_no_time_diff))\n",
    "print('Relative percentage of time diff of no time diff: ' + str(round(number_of_time_diff / (number_of_time_diff + number_of_no_time_diff) * 100, 2)) + ' %')\n",
    "print('Maximum recorded resolution time: ' + str(max(has_time_diff)))\n",
    "print('Lowest recorded resolution time: ' + str(min(has_time_diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "bp = plt.boxplot(life_time_events, sym='+', vert=False, showfliers=False,whis=[5, 95])\n",
    "plt.ylabel('Distribution of resolution time')\n",
    "plt.xlabel('Time in seconds to resolve a warning')\n",
    "plt.xlim([-5, 400])\n",
    "ax.set_yticklabels('')\n",
    "plt.show()\n",
    "fig.savefig('img/life-time-warning-events.png')\n",
    "\n",
    "top_warning_lifetime = defaultdict(list)\n",
    "\n",
    "for event in list(filter(lambda event: event['warning']['diff'] != -1, created_warning_events)):\n",
    "    if (stringify_warning(event['warning']['type']) in top_warning_names):\n",
    "        top_warning_lifetime[stringify_warning(event['warning']['type'])].append(event['warning']['diff'])\n",
    "        \n",
    "category_time_diff_labels, category_time_diff_values = zip(*sorted(top_warning_lifetime.items(), key=lambda tup: -top_warnings.index(tup[0])))\n",
    "category_time_diff_labels = list(map(lambda label: label[:75], category_time_diff_labels))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes()\n",
    "bp = plt.boxplot(category_time_diff_values, sym='+', vert=False, showfliers=False,whis=[5, 95])\n",
    "plt.ylabel('Distribution of resolution time')\n",
    "plt.xlabel('Time in seconds to resolve a warning')\n",
    "plt.xlim([-25, 1000])\n",
    "ax.set_yticklabels(category_time_diff_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('img/life-time-per-category.png')\n",
    "\n",
    "type_resolution_categories = ('Type resolution', [1,  6, 7, 8, 11, 12, 16, 19, 21, 22, 23, 24, 25])\n",
    "unused_declaration_categories = ('Unused declarations/tokens', [9, 14, 15])\n",
    "import_management_categories = ('Import management', [4, 5, 13])\n",
    "\n",
    "def filter_from_category_indices(indices, category_values):\n",
    "    return [value for (index, values) in enumerate(category_values) if ((25 - index) in indices) for value in values]\n",
    "\n",
    "high_level_categories = [import_management_categories, unused_declaration_categories, type_resolution_categories]\n",
    "\n",
    "high_level_category_values = [filter_from_category_indices(categories, category_time_diff_values) for (name, categories) in high_level_categories]\n",
    "high_level_category_labels = [name for (name, categories) in high_level_categories]\n",
    "# print(category_time_diff_labels)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "bp = plt.boxplot(high_level_category_values, sym='+', vert=False, showfliers=False,whis=[5, 95])\n",
    "plt.ylabel('Distribution of resolution time')\n",
    "plt.xlabel('Time in seconds to resolve a warning')\n",
    "plt.xlim([-25, 500])\n",
    "ax.set_yticklabels(high_level_category_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('img/life-time-per-high-level-category.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we print out the number of events per user, as well as the time distribution per user. Filter out all users that do not have enough data yet (e.g. less than 25 events), to obtain a fair representation of their activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_time_per_user = defaultdict(list)\n",
    "for event in created_warning_events:\n",
    "    if event['warning']['diff'] != -1:\n",
    "        life_time_per_user[event['userId']].append(event['warning']['diff'])\n",
    "\n",
    "ordered_life_time_per_user = OrderedDict(sorted(life_time_per_user.items(), key=lambda tup: len(tup[1])))\n",
    "life_time_per_user_values = list(filter(lambda values: len(values) > 25, [ordered_life_time_per_user[user] for user in ordered_life_time_per_user.keys()]))\n",
    "\n",
    "print_dictionary_as_table('{:<40}'.format('User ID'), 'Number of events', ordered_life_time_per_user)\n",
    "print_dictionary_as_table('{:<40}'.format('User ID'), 'Number of events', ordered_life_time_per_user, True)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes()\n",
    "bp = plt.boxplot(life_time_per_user_values, sym='+', vert=False, showfliers=False,notch=False)\n",
    "plt.ylabel('Distribution of resolution time for each user')\n",
    "plt.xlabel('Time in seconds to resolve a warning')\n",
    "plt.xlim([-10,800])\n",
    "ax.set_yticklabels(list(map(lambda user: str(len(ordered_life_time_per_user[user])) + ' events', filter(lambda user: len(ordered_life_time_per_user[user]) > 25, ordered_life_time_per_user.keys()))))\n",
    "plt.show()\n",
    "fig.savefig('img/life-time-for-number-of-events.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to time distribution per user, we also plot the time distribution for the programming experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = defaultdict(str)\n",
    "life_time_per_programming_experience = defaultdict(list)\n",
    "for event in created_warning_events:\n",
    "    if event['warning']['diff'] != -1:\n",
    "        user = list(filter(lambda user: user['id'] == event['userId'], users))\n",
    "        if (len(user) > 0):\n",
    "            unique_users[event['userId']] = user[0]['programmingExperience']\n",
    "            life_time_per_programming_experience[user[0]['programmingExperience']].append(event['warning']['diff'])\n",
    "        else:\n",
    "            print('Could not find user with id: ' + str(event['userId']))\n",
    "\n",
    "life_time_per_programming_experience['N/A'] = life_time_per_programming_experience['N/A'] + life_time_per_programming_experience['NA']\n",
    "del life_time_per_programming_experience['NA']\n",
    "\n",
    "def get_digit_from_string(string):\n",
    "    matcher = re.search(\"(\\d+)\", string)\n",
    "    index = -1\n",
    "    \n",
    "    if \"<\" == string[0]:\n",
    "        index = 0\n",
    "    else:\n",
    "        if \">\" == string[0]:\n",
    "            index = 15\n",
    "        else:\n",
    "            if (matcher):\n",
    "                index = matcher.group(0)\n",
    "\n",
    "    return -int(index)\n",
    "\n",
    "def get_digit_from_tuple(tup):\n",
    "    return get_digit_from_string(tup[0])\n",
    "\n",
    "sorted_keys = sorted(life_time_per_programming_experience.keys(), key=get_digit_from_string)\n",
    "\n",
    "counts_per_exp = [life_time_per_programming_experience[exp] for exp in sorted_keys]\n",
    "\n",
    "print_dictionary_as_table('Programming experience', 'Number of events', OrderedDict(sorted(life_time_per_programming_experience.items(), key=get_digit_from_tuple)))\n",
    "\n",
    "print()\n",
    "\n",
    "programming_exp_user_count = defaultdict(int)\n",
    "for user, exp in unique_users.items():\n",
    "    programming_exp_user_count[exp] = programming_exp_user_count[exp] + 1\n",
    "\n",
    "programming_exp_user_count['N/A'] = programming_exp_user_count['N/A'] + programming_exp_user_count['NA']\n",
    "del programming_exp_user_count['NA']\n",
    "print_dictionary_as_table('Programming experience', 'Number of users', OrderedDict(sorted(programming_exp_user_count.items(), key=get_digit_from_tuple)))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "relative_frequency_per_exp = defaultdict(float)\n",
    "for exp, num_users in programming_exp_user_count.items():\n",
    "    relative_frequency_per_exp[exp] = round(len(life_time_per_programming_experience[exp]) / num_users, 2)\n",
    "\n",
    "print_dictionary_as_table('Programming experience', 'Average number of events per user', OrderedDict(sorted(relative_frequency_per_exp.items(), key=get_digit_from_tuple)))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes()\n",
    "bp = plt.boxplot(counts_per_exp, sym='+', vert=False, showfliers=False,notch=False)\n",
    "plt.ylabel('Distribution of resolution time per user')\n",
    "plt.xlabel('Time in seconds to resolve a warning')\n",
    "ax.set_yticklabels(sorted_keys)\n",
    "plt.show()\n",
    "fig.savefig('img/programming-experience-lifetime.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = [np.array(sorted(np.random.choice(counts, 150))) for counts in counts_per_exp]\n",
    "print(len(counts_per_exp))\n",
    "print(scipy.stats.kruskal(*counts_per_exp[:-1]))\n",
    "print(scipy.stats.ttest_ind(sampled[0],sampled[1]))\n",
    "print(scipy.stats.spearmanr(sampled[:-1], axis=1))\n",
    "print([scipy.stats.normaltest(counts) for counts in sampled])\n",
    "# print(p, p < 3.27207e-11)\n",
    "print(dunn(*counts_per_exp[:-1]))\n",
    "print([np.median(counts) for counts in counts_per_exp[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\"]\n",
    "colors = list(map(lambda state: \"green\" if state == \"Yes\" else \"red\", states))\n",
    "\n",
    "sankey_data = dict(\n",
    "    type='sankey',\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 58,\n",
    "      line = dict(\n",
    "        color = \"black\",\n",
    "        width = 0.5\n",
    "      ),\n",
    "      label = states,\n",
    "      color = colors\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [0 , 0 ,   1, 1,   2 , 2 ,   3, 3,   4 , 4 ,   5 ,   6 , 6 ,   7 , 7 ,   8 ,   9 ,   10,   11,   12,   13, 13,   14, 14,   15,   16,   17],\n",
    "      target = [2 , 3 ,   4, 5,   6 , 7 ,   8, 9,   10, 11,   12,   13, 14,   15, 16,   17,   17,   17,   17,   17,   18, 19,   18, 19,   19,   19,   19],\n",
    "      value =  [38, 11,   5, 4,   18, 20,   6, 5,   2 , 3 ,   4 ,   3 , 15,   2 , 18,   6 ,   5 ,   2 ,   3 ,   4 ,   2 , 1 ,   2 , 13,   2 ,   18,   20]\n",
    "  ))\n",
    "\n",
    "sankey_layout =  dict(\n",
    "    title = \"Basic Sankey Diagram\",\n",
    "    font = dict(\n",
    "      size = 10\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=[sankey_data], layout=sankey_layout)\n",
    "plotly.plotly.iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Yes - 1\", \"Yes - 2\", \"No - 2\", \"Yes - 3\", \"No - 3\", \"Yes - 3\", \"No - 3\", \"Yes - 4\", \"No - 4\", \"Yes - 4\", \"No - 4\", \"Yes - 5\", \"No - 5\"]\n",
    "colors = list(map(lambda state: \"green\" if state[0:3] == \"Yes\" else \"red\", states))\n",
    "\n",
    "sankey_data = dict(\n",
    "    type='sankey',\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 58,\n",
    "      line = dict(\n",
    "        color = \"black\",\n",
    "        width = 0.5\n",
    "      ),\n",
    "      label = states,\n",
    "      color = colors\n",
    "    ),\n",
    "    link = dict(\n",
    "source = [0,0,1,1,2,2,3,3,4,4,5,6,7,7,8,8,9,10],\n",
    "target = [1,2,3,4,5,6,7,8,9,10,10,10,11,12,11,12,12,12],\n",
    "value =  [38,11,18,20,6,5,3,15,2,18,6,5,2,1,2,13,2,29]\n",
    "  ))\n",
    "\n",
    "sankey_layout =  dict(\n",
    "    title = \"Basic Sankey Diagram\",\n",
    "    font = dict(\n",
    "      size = 10\n",
    "    ),\n",
    "    showlegend = True\n",
    ")\n",
    "\n",
    "fig = dict(data=[sankey_data], layout=sankey_layout)\n",
    "plotly.plotly.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcecode = np.array((3, 11, 18, 21, 8))\n",
    "project = np.array((3, 9, 14, 16, 19))\n",
    "ide = np.array((1, 7, 11, 11, 31))\n",
    "\n",
    "fig, (ax,lax) = plt.subplots(nrows=2, gridspec_kw={\"height_ratios\":[10,1]},figsize=(10,5))\n",
    "dataframe = pd.DataFrame(np.asmatrix([ide, project, sourcecode]))\n",
    "fig=dataframe.plot(ax=ax, kind='barh', stacked=True, legend=False)\n",
    "ax.yaxis.set_ticklabels(['IDE', 'Project', 'Source code'])\n",
    "ax.set_xlabel('Number of respondents', fontsize=16)\n",
    "\n",
    "for label in ax.get_yticklabels() + ax.get_xticklabels():\n",
    "    label.set_fontsize(16)\n",
    "plt.tight_layout()\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "lax.legend(h,('Always', 'Often', 'Sometimes', 'Seldom', 'Never'),\n",
    "           borderaxespad=0, mode=\"expand\", ncol=5, prop={'size': 16})\n",
    "lax.axis(\"off\")\n",
    "\n",
    "ax.figure.savefig('img/ignore-configuration-options.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
